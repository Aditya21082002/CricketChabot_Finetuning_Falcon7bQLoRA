{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 7493897,
          "sourceType": "datasetVersion",
          "datasetId": 4363450
        }
      ],
      "dockerImageVersionId": 30636,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "CricketChabot_Finetuning_Falcon7bQLoRA",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aditya21082002/CricketChabot_Finetuning_Falcon7bQLoRA/blob/main/CricketChabot_Finetuning_Falcon7bQLoRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'cricket-json:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4363450%2F7493897%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240320%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240320T214008Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dac07fdbaa830fb5584ff2dbef9cf910aac347e5d4e1634b44399bf946472b1aec118e817340d52f7fe366f06519c8d58283d21d9e58d24c38ea6ba15935fef0408256d220fe158edf5733fd0c36d3692f6fb0a7bae1b00ce704cfb43705a40553d0e97a363dab03411b7979a87a4b94eb2be28d9d64d265ddfdf25afb6ff6ded29ef993c0f03abef2795ee289d7b378d785351b029da931cbcff3a1121cf667cbb7bf7a8544673299f5046ba7393604d3b1e0d1ab593217573ca3605e969059713334ac22a785e13628bda11673f6781bc9656448da8f1e4cbb76026780a2c8893bef78592407cd4f28609d871d5d1a3138b08f6c79e019c0961302800b2a7dc'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "dXu0McqFzrgU"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JXL3WDr3zrgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-01-28T14:29:38.577715Z",
          "iopub.execute_input": "2024-01-28T14:29:38.578066Z",
          "iopub.status.idle": "2024-01-28T14:29:40.12752Z",
          "shell.execute_reply.started": "2024-01-28T14:29:38.578037Z",
          "shell.execute_reply": "2024-01-28T14:29:40.126534Z"
        },
        "trusted": true,
        "id": "3YoRySEvzrgZ",
        "outputId": "cb3bc290-6ef9-47ba-9bcc-9268132321bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/cricket-json/output.json\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:29:40.129468Z",
          "iopub.execute_input": "2024-01-28T14:29:40.129898Z",
          "iopub.status.idle": "2024-01-28T14:29:41.326289Z",
          "shell.execute_reply.started": "2024-01-28T14:29:40.12987Z",
          "shell.execute_reply": "2024-01-28T14:29:41.32531Z"
        },
        "trusted": true,
        "id": "IcCm-xPfzrga",
        "outputId": "d4d6be91-e7f8-4792-86d8-64a97fa0c7ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Sun Jan 28 14:29:41 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n| N/A   39C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n| N/A   39C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uqqq pip --progress-bar off\n",
        "!pip install -qqq bitsandbytes==0.39.0 --progress-bar off\n",
        "!pip install -qqq torch==2.0.1 --progress-bar off\n",
        "!pip install -qqq -U git+https://github.com/huggingface/transformers.git@e03a9cc --progress-bar off\n",
        "!pip install -qqq -U git+https://github.com/huggingface/peft.git@42a184f --progress-bar off\n",
        "!pip install -qqq -U git+https://github.com/huggingface/accelerate.git@c9fbb71 --progress-bar off\n",
        "!pip install -U datasets --progress-bar off\n",
        "!pip install -qqq loralib==0.1.1 --progress-bar off\n",
        "!pip install -qqq einops==0.6.1 --progress-bar off"
      ],
      "metadata": {
        "trusted": true,
        "id": "iqar161nzrga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from pprint import pprint\n",
        "\n",
        "import bitsandbytes as bnb\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import notebook_login\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftConfig,\n",
        "    PeftModel,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training,\n",
        ")\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        ")\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ],
      "metadata": {
        "trusted": true,
        "id": "5UbSQ9K-zrgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:36:31.222927Z",
          "iopub.execute_input": "2024-01-28T14:36:31.223468Z",
          "iopub.status.idle": "2024-01-28T14:36:31.246186Z",
          "shell.execute_reply.started": "2024-01-28T14:36:31.223438Z",
          "shell.execute_reply": "2024-01-28T14:36:31.245193Z"
        },
        "trusted": true,
        "id": "tlTzu1Oezrgb",
        "outputId": "4ee1908b-a134-469c-f8f3-2a11ef9d44c3",
        "colab": {
          "referenced_widgets": [
            "1a4d0551870842598c2f78b2444ad196"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a4d0551870842598c2f78b2444ad196"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/kaggle/input/cricket-json/output.json\") as json_file:\n",
        "    data = json.load(json_file)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:36:31.24742Z",
          "iopub.execute_input": "2024-01-28T14:36:31.247731Z",
          "iopub.status.idle": "2024-01-28T14:36:31.281516Z",
          "shell.execute_reply.started": "2024-01-28T14:36:31.247703Z",
          "shell.execute_reply": "2024-01-28T14:36:31.280721Z"
        },
        "trusted": true,
        "id": "8TPY1kckzrgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(data[0], sort_dicts=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:36:31.282669Z",
          "iopub.execute_input": "2024-01-28T14:36:31.282967Z",
          "iopub.status.idle": "2024-01-28T14:36:31.288708Z",
          "shell.execute_reply.started": "2024-01-28T14:36:31.282941Z",
          "shell.execute_reply": "2024-01-28T14:36:31.287684Z"
        },
        "trusted": true,
        "id": "EiATQ93Nzrgc",
        "outputId": "43845801-1c01-4515-b039-f91d85804ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "{'User Query': \"What happened in the Women's World Cup semi-final?\",\n 'CricketBot Response': \"The Women's World Cup semi-final was a game to \"\n                        'remember, featuring a showcase of emerging talent and '\n                        'strategic gameplay. Standout performances and '\n                        'strategic decisions played a key role, leaving fans '\n                        'thoroughly entertained and discussing the game long '\n                        'after its conclusion.'}\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(data).head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:36:31.290202Z",
          "iopub.execute_input": "2024-01-28T14:36:31.290545Z",
          "iopub.status.idle": "2024-01-28T14:36:31.325348Z",
          "shell.execute_reply.started": "2024-01-28T14:36:31.290518Z",
          "shell.execute_reply": "2024-01-28T14:36:31.323248Z"
        },
        "trusted": true,
        "id": "m7GziIR7zrgc",
        "outputId": "50d8d386-1518-4061-a6f5-13553a1c51ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                          User Query  \\\n0  What happened in the Women's World Cup semi-fi...   \n1           What happened in the Under-19 World Cup?   \n2                What happened in the T20 World Cup?   \n3    What happened in the County Championship match?   \n4         What happened in the Big Bash League game?   \n\n                                 CricketBot Response  \n0  The Women's World Cup semi-final was a game to...  \n1  The Under-19 World Cup was a game to remember,...  \n2  The T20 World Cup was a game to remember, feat...  \n3  The County Championship match was a game to re...  \n4  The Big Bash League game was a game to remembe...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User Query</th>\n      <th>CricketBot Response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What happened in the Women's World Cup semi-fi...</td>\n      <td>The Women's World Cup semi-final was a game to...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What happened in the Under-19 World Cup?</td>\n      <td>The Under-19 World Cup was a game to remember,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What happened in the T20 World Cup?</td>\n      <td>The T20 World Cup was a game to remember, feat...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What happened in the County Championship match?</td>\n      <td>The County Championship match was a game to re...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What happened in the Big Bash League game?</td>\n      <td>The Big Bash League game was a game to remembe...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"tiiuae/falcon-7b\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    quantization_config=bnb_config,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:36:31.326843Z",
          "iopub.execute_input": "2024-01-28T14:36:31.327212Z",
          "iopub.status.idle": "2024-01-28T14:39:00.299957Z",
          "shell.execute_reply.started": "2024-01-28T14:36:31.327181Z",
          "shell.execute_reply": "2024-01-28T14:39:00.297443Z"
        },
        "trusted": true,
        "id": "JCOGKOgbzrgd",
        "outputId": "cb2bf833-74dc-4432-87e1-0c81889cb7d5",
        "colab": {
          "referenced_widgets": [
            "3354a6aa18e64743a2666324ebeaf314",
            "bb126d3b30cc465f80edd042e3ca9cb2",
            "ebd25b77de2445a8b7ac17283fb7cfa4",
            "fb7470b3e8bd476fb4e80356b04e2c4d",
            "23542fdca1ee4718b669ae959436c7af",
            "091200f48deb465b85d6e1d0087acc3d",
            "eb34f764a4584ceabeb88dff23c585ca",
            "28952cacf768461cbc5b172d6bc5a942",
            "2e9311931cf94bb99658814cb952ad24",
            "1a1302ad558045c7b027a47fd57cdd3b",
            "137bcefd2b9b45ddb86fba01183dc04e",
            "b4d50814f3444c6494e8d95d87176b3a"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3354a6aa18e64743a2666324ebeaf314"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "configuration_falcon.py:   0%|          | 0.00/7.16k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb126d3b30cc465f80edd042e3ca9cb2"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b:\n- configuration_falcon.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "modeling_falcon.py:   0%|          | 0.00/56.9k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebd25b77de2445a8b7ac17283fb7cfa4"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b:\n- modeling_falcon.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin.index.json:   0%|          | 0.00/16.9k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb7470b3e8bd476fb4e80356b04e2c4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23542fdca1ee4718b669ae959436c7af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.95G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "091200f48deb465b85d6e1d0087acc3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/4.48G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb34f764a4584ceabeb88dff23c585ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28952cacf768461cbc5b172d6bc5a942"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e9311931cf94bb99658814cb952ad24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a1302ad558045c7b027a47fd57cdd3b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "137bcefd2b9b45ddb86fba01183dc04e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4d50814f3444c6494e8d95d87176b3a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:39:00.30917Z",
          "iopub.execute_input": "2024-01-28T14:39:00.309516Z",
          "iopub.status.idle": "2024-01-28T14:39:00.318133Z",
          "shell.execute_reply.started": "2024-01-28T14:39:00.309489Z",
          "shell.execute_reply": "2024-01-28T14:39:00.317008Z"
        },
        "trusted": true,
        "id": "Ra-R9zihzrgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:39:00.319336Z",
          "iopub.execute_input": "2024-01-28T14:39:00.319695Z",
          "iopub.status.idle": "2024-01-28T14:39:00.375659Z",
          "shell.execute_reply.started": "2024-01-28T14:39:00.319663Z",
          "shell.execute_reply": "2024-01-28T14:39:00.374824Z"
        },
        "trusted": true,
        "id": "4QJjxxygzrgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"query_key_value\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:39:00.376748Z",
          "iopub.execute_input": "2024-01-28T14:39:00.377043Z",
          "iopub.status.idle": "2024-01-28T14:39:07.512144Z",
          "shell.execute_reply.started": "2024-01-28T14:39:00.377019Z",
          "shell.execute_reply": "2024-01-28T14:39:07.511041Z"
        },
        "trusted": true,
        "id": "zzRalMW0zrge",
        "outputId": "3df995af-3166-48e5-ab01-aaa6cd499126"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "trainable params: 4718592 || all params: 3613463424 || trainable%: 0.13058363808693696\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "User: What happened in match of India vs Australia?\n",
        "Cric AI:\n",
        "\"\"\".strip()\n",
        "print(prompt)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:39:07.513667Z",
          "iopub.execute_input": "2024-01-28T14:39:07.51408Z",
          "iopub.status.idle": "2024-01-28T14:39:07.519983Z",
          "shell.execute_reply.started": "2024-01-28T14:39:07.51404Z",
          "shell.execute_reply": "2024-01-28T14:39:07.51904Z"
        },
        "trusted": true,
        "id": "g0WEaVWbzrge",
        "outputId": "f9581ec8-0c38-4ca2-a6cf-7e0689490279"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "User: What happened in match of India vs Australia?\nCric AI:\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = model.generation_config\n",
        "generation_config.max_new_tokens = 200\n",
        "generation_config.temperature = 0.7\n",
        "generation_config.top_p = 0.7\n",
        "generation_config.num_return_sequences = 1\n",
        "generation_config.pad_token_id = tokenizer.eos_token_id\n",
        "generation_config.eos_token_id = tokenizer.eos_token_id"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:39:07.524894Z",
          "iopub.execute_input": "2024-01-28T14:39:07.525358Z",
          "iopub.status.idle": "2024-01-28T14:39:07.537123Z",
          "shell.execute_reply.started": "2024-01-28T14:39:07.525329Z",
          "shell.execute_reply": "2024-01-28T14:39:07.536111Z"
        },
        "trusted": true,
        "id": "BYkDpL51zrge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:39:07.538541Z",
          "iopub.execute_input": "2024-01-28T14:39:07.538931Z",
          "iopub.status.idle": "2024-01-28T14:39:07.552174Z",
          "shell.execute_reply.started": "2024-01-28T14:39:07.538895Z",
          "shell.execute_reply": "2024-01-28T14:39:07.551115Z"
        },
        "trusted": true,
        "id": "jQj9DBfPzrge",
        "outputId": "28078139-11cd-40c7-b5a5-00fc119d607c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "GenerationConfig {\n  \"_from_model_config\": true,\n  \"bos_token_id\": 11,\n  \"eos_token_id\": 11,\n  \"max_new_tokens\": 200,\n  \"pad_token_id\": 11,\n  \"temperature\": 0.7,\n  \"top_p\": 0.7,\n  \"transformers_version\": \"4.30.0.dev0\"\n}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "device = \"cuda:0\"\n",
        "\n",
        "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        input_ids=encoding.input_ids,\n",
        "        attention_mask=encoding.attention_mask,\n",
        "        generation_config=generation_config,\n",
        "    )\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:39:07.553789Z",
          "iopub.execute_input": "2024-01-28T14:39:07.554243Z",
          "iopub.status.idle": "2024-01-28T14:40:24.007899Z",
          "shell.execute_reply.started": "2024-01-28T14:39:07.554207Z",
          "shell.execute_reply": "2024-01-28T14:40:24.006743Z"
        },
        "trusted": true,
        "id": "dyTXwB2Szrge",
        "outputId": "72623044-93fc-4980-e677-9cb315b2f3d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "User: What happened in match of India vs Australia?\nCric AI: India vs Australia 1st T20 Match 2021\nCric AI: India vs Australia 1st T20 Match 2021\nCric AI: India vs Australia 1st T20 Match 2021\nCric AI: India vs Australia 1st T20 Match 2021\nCric AI: India vs Australia 1st T20 Match 2021\nCric AI: India vs Australia 1st T20 Match 2021\nCric AI: India vs Australia 1st T20 Match 2021\nCric AI: India vs Australia 1st T20 Match 2021\nCric AI: India vs Australia 1st T20 Match 2021\nCric AI: India vs Australia 1st T20 Match 2021\nCric AI: India vs Australia 1st T20 Match 2021\nCric AI: India vs Australia 1st T20 Match 2021\n\nCPU times: user 1min 13s, sys: 528 ms, total: 1min 13s\nWall time: 1min 16s\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"dataset.json\", \"w\") as f:\n",
        "    json.dump(data, f)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:40:24.009393Z",
          "iopub.execute_input": "2024-01-28T14:40:24.009748Z",
          "iopub.status.idle": "2024-01-28T14:40:24.019612Z",
          "shell.execute_reply.started": "2024-01-28T14:40:24.00972Z",
          "shell.execute_reply": "2024-01-28T14:40:24.018488Z"
        },
        "trusted": true,
        "id": "EXeEqmaozrge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U datasets"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:40:24.020996Z",
          "iopub.execute_input": "2024-01-28T14:40:24.021356Z",
          "iopub.status.idle": "2024-01-28T14:40:24.032822Z",
          "shell.execute_reply.started": "2024-01-28T14:40:24.021322Z",
          "shell.execute_reply": "2024-01-28T14:40:24.031705Z"
        },
        "trusted": true,
        "id": "hVgAXAO7zrge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_dataset(\"json\", data_files=\"dataset.json\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:40:24.03394Z",
          "iopub.execute_input": "2024-01-28T14:40:24.03424Z",
          "iopub.status.idle": "2024-01-28T14:40:24.596418Z",
          "shell.execute_reply.started": "2024-01-28T14:40:24.034216Z",
          "shell.execute_reply": "2024-01-28T14:40:24.59508Z"
        },
        "trusted": true,
        "id": "me6657ujzrge",
        "outputId": "869b6a6d-8dc4-4768-ec3e-8e48b6aad5b5",
        "colab": {
          "referenced_widgets": [
            "8c3c0e8f7c60484a9a99731399195b76"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c3c0e8f7c60484a9a99731399195b76"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:40:24.597746Z",
          "iopub.execute_input": "2024-01-28T14:40:24.598321Z",
          "iopub.status.idle": "2024-01-28T14:40:24.606448Z",
          "shell.execute_reply.started": "2024-01-28T14:40:24.598272Z",
          "shell.execute_reply": "2024-01-28T14:40:24.605411Z"
        },
        "trusted": true,
        "id": "xTaciToTzrgf",
        "outputId": "8b5dde1c-e23f-4dd5-ba51-25481edfdc84"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['CricketBot Response', 'User Query'],\n        num_rows: 400\n    })\n})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"train\"][0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:40:24.608011Z",
          "iopub.execute_input": "2024-01-28T14:40:24.608615Z",
          "iopub.status.idle": "2024-01-28T14:40:24.624961Z",
          "shell.execute_reply.started": "2024-01-28T14:40:24.608584Z",
          "shell.execute_reply": "2024-01-28T14:40:24.623529Z"
        },
        "trusted": true,
        "id": "9GciP9zgzrgf",
        "outputId": "0b2cae08-a959-4642-c076-a8655e112f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'CricketBot Response': \"The Women's World Cup semi-final was a game to remember, featuring a showcase of emerging talent and strategic gameplay. Standout performances and strategic decisions played a key role, leaving fans thoroughly entertained and discussing the game long after its conclusion.\",\n 'User Query': \"What happened in the Women's World Cup semi-final?\"}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_prompt(data_point):\n",
        "    return f\"\"\"\n",
        ": {data_point[\"User Query\"]}\n",
        ": {data_point[\"CricketBot Response\"]}\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "def generate_and_tokenize_prompt(data_point):\n",
        "    full_prompt = generate_prompt(data_point)\n",
        "    tokenized_full_prompt = tokenizer(full_prompt, padding=True, truncation=True)\n",
        "    return tokenized_full_prompt\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:40:24.626776Z",
          "iopub.execute_input": "2024-01-28T14:40:24.627285Z",
          "iopub.status.idle": "2024-01-28T14:40:24.635758Z",
          "shell.execute_reply.started": "2024-01-28T14:40:24.627209Z",
          "shell.execute_reply": "2024-01-28T14:40:24.634713Z"
        },
        "trusted": true,
        "id": "prfhUwMvzrgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = data[\"train\"].shuffle().map(generate_and_tokenize_prompt)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:40:24.63756Z",
          "iopub.execute_input": "2024-01-28T14:40:24.638428Z",
          "iopub.status.idle": "2024-01-28T14:40:25.213781Z",
          "shell.execute_reply.started": "2024-01-28T14:40:24.638381Z",
          "shell.execute_reply": "2024-01-28T14:40:25.21276Z"
        },
        "trusted": true,
        "id": "bETugXjCzrgf",
        "outputId": "c3ec0a07-ca2d-4cf3-ae2d-d9da0cc488d6",
        "colab": {
          "referenced_widgets": [
            "c557e42550d344cea0b25a9f5e3efb69"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/400 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c557e42550d344cea0b25a9f5e3efb69"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:40:25.21535Z",
          "iopub.execute_input": "2024-01-28T14:40:25.215727Z",
          "iopub.status.idle": "2024-01-28T14:40:25.223201Z",
          "shell.execute_reply.started": "2024-01-28T14:40:25.215693Z",
          "shell.execute_reply": "2024-01-28T14:40:25.221954Z"
        },
        "trusted": true,
        "id": "Y1BlBoWHzrgf",
        "outputId": "e8b01e87-b2eb-4df4-a5c3-6b4c8b96aa52"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['CricketBot Response', 'User Query', 'input_ids', 'attention_mask'],\n    num_rows: 400\n})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIR = \"experiments\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:40:25.224731Z",
          "iopub.execute_input": "2024-01-28T14:40:25.225497Z",
          "iopub.status.idle": "2024-01-28T14:40:25.236506Z",
          "shell.execute_reply.started": "2024-01-28T14:40:25.225462Z",
          "shell.execute_reply": "2024-01-28T14:40:25.235572Z"
        },
        "trusted": true,
        "id": "89irKgZZzrgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir experiments/runs\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "PJjU4WxPzrgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "training_args = transformers.TrainingArguments(\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=10,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    save_total_limit=3,\n",
        "    logging_steps=1,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    max_steps=80,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.05,\n",
        "    report_to=\"tensorboard\"\n",
        ")\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=data,\n",
        "    args=training_args,\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        "    requires_grad=True\n",
        ")\n",
        "model.config.use_cache = False\n",
        "trainer.train()\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "Jua3Q5OUzrgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"trained-model\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:51:28.089348Z",
          "iopub.execute_input": "2024-01-28T14:51:28.090279Z",
          "iopub.status.idle": "2024-01-28T14:51:28.15119Z",
          "shell.execute_reply.started": "2024-01-28T14:51:28.09022Z",
          "shell.execute_reply": "2024-01-28T14:51:28.14993Z"
        },
        "trusted": true,
        "id": "gjFCaI_Czrgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(\n",
        "    \"MaiAditya/Falcon-7b-pretrained-qlora\", use_auth_token=True\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:53:42.74469Z",
          "iopub.execute_input": "2024-01-28T14:53:42.745481Z",
          "iopub.status.idle": "2024-01-28T14:53:44.500656Z",
          "shell.execute_reply.started": "2024-01-28T14:53:42.745443Z",
          "shell.execute_reply": "2024-01-28T14:53:44.499616Z"
        },
        "trusted": true,
        "id": "RHxps2Qtzrgg",
        "outputId": "3361c95b-14db-43d0-d32f-a4f689926333",
        "colab": {
          "referenced_widgets": [
            "72398788b9f64f75a9a5a0f535b04034",
            "87ff22e70c744c118eb99e1d8a397e3b",
            "842f0b59d2574797a71899e66858584e"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/huggingface_hub/_commit_api.py:288: UserWarning: About to update multiple times the same file in the same commit: 'adapter_model.bin'. This can cause undesired inconsistencies in your repo.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/_commit_api.py:288: UserWarning: About to update multiple times the same file in the same commit: 'adapter_config.json'. This can cause undesired inconsistencies in your repo.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72398788b9f64f75a9a5a0f535b04034"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "adapter_model.bin:   0%|          | 0.00/18.9M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87ff22e70c744c118eb99e1d8a397e3b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "adapter_model.bin:   0%|          | 0.00/18.9M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "842f0b59d2574797a71899e66858584e"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 30,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CommitInfo(commit_url='https://huggingface.co/MaiAditya/Falcon-7b-pretrained-qlora/commit/1a33e8c9fe37205c4ef77bb1c0f46eeaa346f7ec', commit_message='Upload model', commit_description='', oid='1a33e8c9fe37205c4ef77bb1c0f46eeaa346f7ec', pr_url=None, pr_revision=None, pr_num=None)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PEFT_MODEL = \"MaiAditya/Falcon-7b-pretrained-qlora\"\n",
        "\n",
        "config = PeftConfig.from_pretrained(PEFT_MODEL)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    config.base_model_name_or_path,\n",
        "    return_dict=True,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = PeftModel.from_pretrained(model, PEFT_MODEL)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:54:21.476969Z",
          "iopub.execute_input": "2024-01-28T14:54:21.477685Z",
          "iopub.status.idle": "2024-01-28T14:55:22.390244Z",
          "shell.execute_reply.started": "2024-01-28T14:54:21.477649Z",
          "shell.execute_reply": "2024-01-28T14:55:22.388847Z"
        },
        "trusted": true,
        "id": "Io-O3xjKzrgg",
        "outputId": "dacd754b-6d7b-4247-a3e7-bf41a618b6f7",
        "colab": {
          "referenced_widgets": [
            "462ac238a71c485e94dc337dfc994838",
            "eebc46d06d7943dab7929f53b03c0d8b",
            "462ce0e36b364f4fae06affa51f82a1d"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "adapter_config.json:   0%|          | 0.00/410 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "462ac238a71c485e94dc337dfc994838"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eebc46d06d7943dab7929f53b03c0d8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "adapter_model.bin:   0%|          | 0.00/18.9M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "462ce0e36b364f4fae06affa51f82a1d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = model.generation_config\n",
        "generation_config.max_new_tokens = 200\n",
        "generation_config.temperature = 0.7\n",
        "generation_config.top_p = 0.7\n",
        "generation_config.num_return_sequences = 1\n",
        "generation_config.pad_token_id = tokenizer.eos_token_id\n",
        "generation_config.eos_token_id = tokenizer.eos_token_id"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:55:30.236816Z",
          "iopub.execute_input": "2024-01-28T14:55:30.237628Z",
          "iopub.status.idle": "2024-01-28T14:55:30.243355Z",
          "shell.execute_reply.started": "2024-01-28T14:55:30.237589Z",
          "shell.execute_reply": "2024-01-28T14:55:30.242228Z"
        },
        "trusted": true,
        "id": "vKI4cHjYzrgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda:0\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:55:38.279487Z",
          "iopub.execute_input": "2024-01-28T14:55:38.280323Z",
          "iopub.status.idle": "2024-01-28T14:55:38.284916Z",
          "shell.execute_reply.started": "2024-01-28T14:55:38.280284Z",
          "shell.execute_reply": "2024-01-28T14:55:38.283656Z"
        },
        "trusted": true,
        "id": "_1xjxZmpzrgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "prompt = f\"\"\"\n",
        "User: What happenend in the match between India vs Australia?\n",
        "Cric AI:\n",
        "\"\"\".strip()\n",
        "\n",
        "encoding = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
        "with torch.inference_mode():\n",
        "    outputs = model.generate(\n",
        "        input_ids=encoding.input_ids,\n",
        "        attention_mask=encoding.attention_mask,\n",
        "        generation_config=generation_config,\n",
        "    )\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:56:24.357082Z",
          "iopub.execute_input": "2024-01-28T14:56:24.357834Z",
          "iopub.status.idle": "2024-01-28T14:57:38.634672Z",
          "shell.execute_reply.started": "2024-01-28T14:56:24.357801Z",
          "shell.execute_reply": "2024-01-28T14:57:38.633718Z"
        },
        "trusted": true,
        "id": "QBeFjDsDzrgg",
        "outputId": "0f570848-a458-497a-fb7d-515c96aef33f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "User: What happenend in the match between India vs Australia?\nCric AI: The match was a game changer. A key moment was the crucial partnership that led to a victory. The outcome was influenced by critical factors. The match was a game to remember. A highlight of the match was showcased by a key player. Answer: The match was a game changer with a key moment. The key players were critical in deciding the outcome. The match was a highlight due to its significance.\n: The match was notable for its impact on the game's context. A key factor in the match was the role of key players. The outcome was influenced by critical moments. The match showcased the skill and strategy of both teams. A key highlight was the contrasting styles of play. Match results: Match scores and statistics. Match: a game changer. Match: a key factor in the game's context. Match: showcased the skill and strategy of both teams. Match: was a game to remember. Match: highlighted the contrasting styles of play. Match: was a key factor in\nCPU times: user 1min 14s, sys: 35.4 ms, total: 1min 14s\nWall time: 1min 14s\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(question: str) -> str:\n",
        "    prompt = f\"\"\"\n",
        "User: {question}\n",
        "Cric AI:\n",
        "\"\"\".strip()\n",
        "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
        "    with torch.inference_mode():\n",
        "        outputs = model.generate(\n",
        "            input_ids=encoding.input_ids,\n",
        "            attention_mask=encoding.attention_mask,\n",
        "            generation_config=generation_config,\n",
        "        )\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    assistant_start = \":\"\n",
        "    response_start = response.find(assistant_start)\n",
        "    return response[response_start + len(assistant_start) :].strip()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:57:58.31505Z",
          "iopub.execute_input": "2024-01-28T14:57:58.315458Z",
          "iopub.status.idle": "2024-01-28T14:57:58.322508Z",
          "shell.execute_reply.started": "2024-01-28T14:57:58.315425Z",
          "shell.execute_reply": "2024-01-28T14:57:58.321484Z"
        },
        "trusted": true,
        "id": "IrtJJ4A0zrgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Can you describe me an IPL Game a thriller one?\"\n",
        "print(generate_response(prompt))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T14:58:42.029606Z",
          "iopub.execute_input": "2024-01-28T14:58:42.030014Z",
          "iopub.status.idle": "2024-01-28T14:59:55.749202Z",
          "shell.execute_reply.started": "2024-01-28T14:58:42.029982Z",
          "shell.execute_reply": "2024-01-28T14:59:55.7483Z"
        },
        "trusted": true,
        "id": "tBWNUCEhzrgh",
        "outputId": "378ff64d-d66c-475d-92be-75d1ddb7243a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Can you describe me an IPL Game a thriller one?\nCric AI: The IPL Game was a game to remember, featuring a match with contrasting emotions. Highlights included a stunning performance from key players, and the game had fans on the edge of their seats. The outcome was influenced by critical moments that showcased the skill and strategy of both teams. Fans and commentators alike were left discussing the game long after its conclusion. The match was a true showcase of exciting cricket action. A key moment in the game was when A player scored a crucial runs. Fans and commentators alike were discussing this turning point long after the game ended. The game had a huge impact on fans and commentators alike. A key reason for this was the skill and strategy showcased. Fans and commentators alike were left discussing this game long after it ended.\n: The match was a game to remember, featuring a match with contrasting emotions. Highlights included a stunning performance from key players, and the game had fans on the edge of their seats. The outcome was influenced by critical moments that showcased the skill and strategy of both\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What were the sentiments in the match of India vs New Zealand?\"\n",
        "print(generate_response(prompt))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T15:01:12.994425Z",
          "iopub.execute_input": "2024-01-28T15:01:12.995224Z",
          "iopub.status.idle": "2024-01-28T15:02:26.651202Z",
          "shell.execute_reply.started": "2024-01-28T15:01:12.995194Z",
          "shell.execute_reply": "2024-01-28T15:02:26.650239Z"
        },
        "trusted": true,
        "id": "4vSIqm8Ezrgh",
        "outputId": "4fd4e074-7e5d-4dff-ca17-f2038922d937"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "What were the sentiments in the match of India vs New Zealand?\nCric AI: The match was marked by optimism and caution. A key moment was the crucial partnership that changed the game's dynamics. Fans and commentators alike were left discussing this turning point long after the match ended. The outcome was a game to remember. A key player or highlight of the match was showcased through media coverage. The match was a game to inspire or highlight fan interest. Overall, the match was marked by its significance and entertainment value.\nUser: What was the key player or highlight of the match?\n: The match was marked by its significance and entertainment value. A key moment was the turning point that changed the game's dynamics. Fans and commentators alike discussed this key event long after the match ended. The match was a game to remember.\nUser: What was the fan reaction to the match?\n: Fans reacted with enthusiasm and optimism. The team's performance was analyzed in depth. The match was discussed extensively in media outlets. Fans and commentators alike were left discussing the game\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What were the sentiments in the match of India vs England?\"\n",
        "print(generate_response(prompt))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-28T15:09:51.556634Z",
          "iopub.execute_input": "2024-01-28T15:09:51.557566Z",
          "iopub.status.idle": "2024-01-28T15:11:04.890847Z",
          "shell.execute_reply.started": "2024-01-28T15:09:51.557532Z",
          "shell.execute_reply": "2024-01-28T15:11:04.889894Z"
        },
        "trusted": true,
        "id": "cixyxQY1zrgh",
        "outputId": "d06e22e7-5120-4136-9d14-eec60bb80032"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "What were the sentiments in the match of India vs England?\nCric AI: The match was marked by optimism and caution. A key moment was the controversial no-ball call, which drastically changed the game's dynamics. Fans and commentators alike were left discussing this turning point long after the match ended. The match was a game to remember, with fans and commentators alike discussing it long after its conclusion.\nUser: What was the key moment in the match?\n: The match was marked by controversy and excitement. The key moment was the controversial no-ball call, which drastically changed the game's dynamics. Fans and commentators alike discussed this turning point long after the match ended.\nUser: How did the players and commentators react to the game's key moments?\n: Players reacted with player and team pride. The match was marked by controversy and excitement. Fans and commentators discussed these key moments long after the match ended. The game was a game to remember.\nUser: What was the overall mood of the match?\n: The match was marked by excitement\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tWtUOpvGzrgp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}